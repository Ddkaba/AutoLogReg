{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP21+jzqlHbMjlwStg7vVhg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ddkaba/AutoLogReg/blob/main/AutoLogReg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PdiafTnIpf2a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import patoolib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.multioutput import ClassifierChain\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import (\n",
        "    hamming_loss, f1_score, precision_score, recall_score, classification_report\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Укажите имя вашего RAR-архива\n",
        "rar_file = 'complaints.rar'  # замените на имя вашего файла\n",
        "\n",
        "# Распакуйте архив в папку 'extracted_files'\n",
        "patoolib.extract_archive(rar_file, outdir='extracted_files')\n",
        "\n",
        "# Укажите имя CSV-файла, который вы хотите прочитать\n",
        "csv_file = 'extracted_files/complaints.csv'  # замените на имя вашего CSV-файла\n",
        "\n",
        "# Прочитайте CSV-файл\n",
        "cars_df = pd.read_csv(csv_file)\n",
        "\n",
        "# Посмотрите первые 5 строк\n",
        "print(cars_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW6m7bLyp4kP",
        "outputId": "8d992ed1-57d3-4934-ab40-c8b49bf62bd0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO patool: Extracting complaints.rar ...\n",
            "INFO:patool:Extracting complaints.rar ...\n",
            "INFO patool: running /usr/bin/unrar x -kb -or -- /content/complaints.rar\n",
            "INFO:patool:running /usr/bin/unrar x -kb -or -- /content/complaints.rar\n",
            "INFO patool: ... complaints.rar extracted to `extracted_files'.\n",
            "INFO:patool:... complaints.rar extracted to `extracted_files'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   odiNumber                manufacturer  crash   fire  numberOfInjuries  \\\n",
            "0   10702705           Kia America, Inc.   True  False                 0   \n",
            "1   10713088           Kia America, Inc.  False  False                 0   \n",
            "2   10713503    ALUMA TOWER COMPANY, INC  False   True                 0   \n",
            "3   10715078           Kia America, Inc.  False  False                 0   \n",
            "4   10715844  Volvo Trucks North America  False  False                 0   \n",
            "\n",
            "   numberOfDeaths dateOfIncident dateComplaintFiled          vin  \\\n",
            "0               0     03/24/2015         03/30/2015  5XYPG4A36GG   \n",
            "1               0     04/24/2015         04/27/2015  5XYPH4A15GG   \n",
            "2               0     04/28/2015         04/29/2015  1YGAE1629GB   \n",
            "3               0     04/30/2015         05/07/2015          NaN   \n",
            "4               0     03/06/2015         05/12/2015  4V4NC9EH7GN   \n",
            "\n",
            "          components                                            summary  \\\n",
            "0   SEAT BELTS,SEATS        SEAT BELT DID NOT UNLATCH AFTER CRASH.  *TR   \n",
            "1          STRUCTURE  TRAVELING AT HIGHWAY SPEED, THE WINDSHIELD SEE...   \n",
            "2  ELECTRICAL SYSTEM  TL* THE CONTACT OWNS A 2016 ALUMA AE716TA TRAI...   \n",
            "3           STEERING  WHILE TRAVELING AT HIGHWAY SPEEDS, THE SORENTO...   \n",
            "4         SUSPENSION  SINCE THE PURCHASE OF THIS VEHICLE IT HAS AN U...   \n",
            "\n",
            "                                            products   make    model  \\\n",
            "0  [{\"type\": \"Vehicle\", \"productYear\": \"2016\", \"p...    KIA  SORENTO   \n",
            "1  [{\"type\": \"Vehicle\", \"productYear\": \"2016\", \"p...    KIA  SORENTO   \n",
            "2  [{\"type\": \"Vehicle\", \"productYear\": \"2016\", \"p...  ALUMA  AE716TA   \n",
            "3  [{\"type\": \"Vehicle\", \"productYear\": \"2016\", \"p...    KIA  SORENTO   \n",
            "4  [{\"type\": \"Vehicle\", \"productYear\": \"2016\", \"p...  VOLVO      780   \n",
            "\n",
            "   modelYear  \n",
            "0       2016  \n",
            "1       2016  \n",
            "2       2016  \n",
            "3       2016  \n",
            "4       2016  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Общая информация\")\n",
        "print(cars_df.info())\n",
        "\n",
        "print(f\"Количество записей (объектов): {cars_df.shape[0]}\")\n",
        "print(f\"Количество признаков (фич): {cars_df.shape[1]}\")\n",
        "\n",
        "print(\"\\nНазвания столбцов:\")\n",
        "print(cars_df.columns.tolist())\n",
        "\n",
        "print(\"\\nТипы данных:\")\n",
        "print(cars_df.dtypes)\n",
        "\n",
        "print(\"\\nПропущенные значения:\")\n",
        "missing_values = cars_df.isnull().sum()\n",
        "print(missing_values)\n",
        "print(f\"Общее количество пропущенных значений: {missing_values.sum()}\")\n",
        "\n",
        "print(\"Целевая переменная\")\n",
        "target_column = 'components'\n",
        "if target_column in cars_df.columns:\n",
        "    print(f\"\\nЦелевая переменная: {target_column}\")\n",
        "    print(f\"Тип данных целевой переменной: {cars_df[target_column].dtype}\")\n",
        "    unique_values = cars_df[target_column].unique()\n",
        "    print(f\"Уникальные значения целевой переменной (первые 20): {unique_values[:20]}\")\n",
        "    print(f\"Всего уникальных значений: {unique_values.size}\")\n",
        "    if cars_df[target_column].nunique() <= 20:\n",
        "        print(\"Распределение классов:\")\n",
        "        print(cars_df[target_column].value_counts())\n",
        "        print(\"Процентное соотношение классов:\")\n",
        "        print(cars_df[target_column].value_counts(normalize=True) * 100)\n",
        "\n",
        "print(\"Статистика\")\n",
        "print(cars_df.describe())\n",
        "\n",
        "print(\"Анализ кат. признаков\")\n",
        "categorical_features = []\n",
        "for col in cars_df.columns:\n",
        "    unique_values = cars_df[col].nunique(dropna=True)\n",
        "    if unique_values <= 10:\n",
        "        categorical_features.append(col)\n",
        "        print(f\"{col}: {unique_values} уникальных значений - {cars_df[col].unique()}\")\n",
        "\n",
        "print(f\"\\nВсего категориальных признаков: {len(categorical_features)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10JQ5ucvqSG5",
        "outputId": "648b05eb-202c-4f99-c733-d19d746016ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Общая информация\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 233820 entries, 0 to 233819\n",
            "Data columns (total 15 columns):\n",
            " #   Column              Non-Null Count   Dtype \n",
            "---  ------              --------------   ----- \n",
            " 0   odiNumber           233820 non-null  int64 \n",
            " 1   manufacturer        233802 non-null  object\n",
            " 2   crash               233820 non-null  bool  \n",
            " 3   fire                233820 non-null  bool  \n",
            " 4   numberOfInjuries    233820 non-null  int64 \n",
            " 5   numberOfDeaths      233820 non-null  int64 \n",
            " 6   dateOfIncident      233820 non-null  object\n",
            " 7   dateComplaintFiled  233820 non-null  object\n",
            " 8   vin                 228677 non-null  object\n",
            " 9   components          233810 non-null  object\n",
            " 10  summary             233809 non-null  object\n",
            " 11  products            233820 non-null  object\n",
            " 12  make                233820 non-null  object\n",
            " 13  model               233820 non-null  object\n",
            " 14  modelYear           233820 non-null  int64 \n",
            "dtypes: bool(2), int64(4), object(9)\n",
            "memory usage: 23.6+ MB\n",
            "None\n",
            "Количество записей (объектов): 233820\n",
            "Количество признаков (фич): 15\n",
            "\n",
            "Названия столбцов:\n",
            "['odiNumber', 'manufacturer', 'crash', 'fire', 'numberOfInjuries', 'numberOfDeaths', 'dateOfIncident', 'dateComplaintFiled', 'vin', 'components', 'summary', 'products', 'make', 'model', 'modelYear']\n",
            "\n",
            "Типы данных:\n",
            "odiNumber              int64\n",
            "manufacturer          object\n",
            "crash                   bool\n",
            "fire                    bool\n",
            "numberOfInjuries       int64\n",
            "numberOfDeaths         int64\n",
            "dateOfIncident        object\n",
            "dateComplaintFiled    object\n",
            "vin                   object\n",
            "components            object\n",
            "summary               object\n",
            "products              object\n",
            "make                  object\n",
            "model                 object\n",
            "modelYear              int64\n",
            "dtype: object\n",
            "\n",
            "Пропущенные значения:\n",
            "odiNumber                0\n",
            "manufacturer            18\n",
            "crash                    0\n",
            "fire                     0\n",
            "numberOfInjuries         0\n",
            "numberOfDeaths           0\n",
            "dateOfIncident           0\n",
            "dateComplaintFiled       0\n",
            "vin                   5143\n",
            "components              10\n",
            "summary                 11\n",
            "products                 0\n",
            "make                     0\n",
            "model                    0\n",
            "modelYear                0\n",
            "dtype: int64\n",
            "Общее количество пропущенных значений: 5182\n",
            "Целевая переменная\n",
            "\n",
            "Целевая переменная: components\n",
            "Тип данных целевой переменной: object\n",
            "Уникальные значения целевой переменной (первые 20): ['SEAT BELTS,SEATS' 'STRUCTURE' 'ELECTRICAL SYSTEM' 'STEERING'\n",
            " 'SUSPENSION' 'VEHICLE SPEED CONTROL' 'VISIBILITY/WIPER' 'VISIBILITY'\n",
            " 'SERVICE BRAKES' 'WHEELS' 'POWER TRAIN'\n",
            " 'ELECTRICAL SYSTEM,UNKNOWN OR OTHER,ELECTRONIC STABILITY CONTROL (ESC)'\n",
            " 'UNKNOWN OR OTHER' 'AIR BAGS,SEATS' 'UNKNOWN OR OTHER,VISIBILITY/WIPER'\n",
            " 'ELECTRICAL SYSTEM,ENGINE' 'FUEL SYSTEM, GASOLINE,POWER TRAIN'\n",
            " 'POWER TRAIN,UNKNOWN OR OTHER,ENGINE' 'UNKNOWN OR OTHER,SERVICE BRAKES'\n",
            " 'ELECTRICAL SYSTEM,SERVICE BRAKES']\n",
            "Всего уникальных значений: 2212\n",
            "Статистика\n",
            "          odiNumber  numberOfInjuries  numberOfDeaths      modelYear\n",
            "count  2.338200e+05     233820.000000   233820.000000  233820.000000\n",
            "mean   1.147072e+07          0.036917        0.000928    2018.919541\n",
            "std    1.835732e+05          0.283581        0.041711       2.442786\n",
            "min    1.070270e+07          0.000000        0.000000    2016.000000\n",
            "25%    1.138277e+07          0.000000        0.000000    2017.000000\n",
            "50%    1.151682e+07          0.000000        0.000000    2018.000000\n",
            "75%    1.161340e+07          0.000000        0.000000    2021.000000\n",
            "max    1.169708e+07         40.000000        8.000000    2026.000000\n",
            "Анализ кат. признаков\n",
            "crash: 2 уникальных значений - [ True False]\n",
            "fire: 2 уникальных значений - [False  True]\n",
            "numberOfDeaths: 8 уникальных значений - [0 1 2 3 8 4 6 5]\n",
            "\n",
            "Всего категориальных признаков: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаление нерелевантных признаков\n",
        "cols_to_drop = ['odiNumber', 'manufacturer', 'vin', 'products', 'dateOfIncident','dateComplaintFiled']\n",
        "\n",
        "# Выбираем рабочий датафрейм: если уже есть сгенерированный (cars_df), используем его,\n",
        "# иначе — исходный cars_df.\n",
        "df_ref = cars_df if 'dataset' in globals() else cars_df\n",
        "\n",
        "print('До:', df_ref.shape)\n",
        "# Удаляем только те признаки, которые реально присутствуют в датафрейме\n",
        "df_ref.drop(columns=[c for c in cols_to_drop if c in df_ref.columns], axis=1, inplace=True)\n",
        "print('После:', df_ref.shape)\n",
        "print('Текущие столбцы:')\n",
        "print(df_ref.columns.tolist())\n",
        "\n",
        "# Если мы работаем с исходным dataset (dataset отсутствует),\n",
        "# обновляем его, чтобы изменения сохранились.\n",
        "if 'cars_df' not in globals():\n",
        "    cars_df = df_ref"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYze2luqsNSm",
        "outputId": "cb4942a2-55ac-460b-96f4-0eca21bb8f13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "До: (233820, 15)\n",
            "После: (233820, 9)\n",
            "Текущие столбцы:\n",
            "['crash', 'fire', 'numberOfInjuries', 'numberOfDeaths', 'components', 'summary', 'make', 'model', 'modelYear']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cars_df = cars_df.dropna(subset=['components'])\n",
        "print(cars_df.shape)\n",
        "cars_df = cars_df.copy()\n",
        "cars_df['num_components'] = cars_df['components'].apply(lambda x: len(x.split(',')) if isinstance(x, str) else 0)\n",
        "print(cars_df.shape)\n",
        "print('Текущие столбцы:')\n",
        "print(cars_df.columns.tolist())"
      ],
      "metadata": {
        "id": "6u9XQ8z7u3JV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5382de8e-feee-45e4-e8a9-a07033207e10"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(233810, 9)\n",
            "(233810, 10)\n",
            "Текущие столбцы:\n",
            "['crash', 'fire', 'numberOfInjuries', 'numberOfDeaths', 'components', 'summary', 'make', 'model', 'modelYear', 'num_components']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_features(dataset):\n",
        "    \"\"\"\n",
        "    Стандартизирует числовые признаки в датасете (z = (x - mean) / std).\n",
        "\n",
        "    Параметры:\n",
        "        dataset (pd.DataFrame): Входной датасет.\n",
        "\n",
        "    Возвращает:\n",
        "        pd.DataFrame: Стандартизированный датасет.\n",
        "    \"\"\"\n",
        "    # Создаем копию, чтобы не изменять оригинал\n",
        "    base_df = dataset.copy()\n",
        "\n",
        "    # Отбираем числовые признаки\n",
        "    feature_cols = base_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "    # Проверка, есть ли числовые признаки\n",
        "    if not feature_cols:\n",
        "        raise ValueError(\"В датасете нет числовых признаков для стандартизации.\")\n",
        "\n",
        "    # Стандартизация\n",
        "    scaler = StandardScaler()\n",
        "    scaled = scaler.fit_transform(base_df[feature_cols])\n",
        "\n",
        "    # Создаем DataFrame с стандартизированными признаками\n",
        "    standardized_df = pd.DataFrame(scaled, columns=feature_cols, index=base_df.index)\n",
        "\n",
        "    # Возвращаем все столбцы, заменяя числовые на стандартизированные\n",
        "    base_df[feature_cols] = standardized_df[feature_cols]\n",
        "\n",
        "    # Вывод информации\n",
        "    print('Стандартизированы признаки:', feature_cols)\n",
        "    print('Форма:', standardized_df.shape)\n",
        "\n",
        "    # Проверка средних и стандартных отклонений\n",
        "    means = base_df[feature_cols].mean().round(4)\n",
        "    stdevs = base_df[feature_cols].std(ddof=0).round(4)\n",
        "    print('\\nСредние по столбцам (ожид. ≈ 0):')\n",
        "    print(means)\n",
        "    print('\\nСт. отклонения (ожид. ≈ 1):')\n",
        "    print(stdevs)\n",
        "    print('\\n')\n",
        "\n",
        "    return base_df\n",
        "\n",
        "# Пример использования\n",
        "cars_df_standardized = standardize_features(cars_df)\n",
        "\n",
        "print(\"\\nТипы данных:\")\n",
        "print(cars_df_standardized.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQQZLJZdvZHV",
        "outputId": "7968636c-75b0-470e-d834-3d732856f3af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Стандартизированы признаки: ['numberOfInjuries', 'numberOfDeaths', 'modelYear', 'num_components']\n",
            "Форма: (233810, 4)\n",
            "\n",
            "Средние по столбцам (ожид. ≈ 0):\n",
            "numberOfInjuries    0.0\n",
            "numberOfDeaths      0.0\n",
            "modelYear          -0.0\n",
            "num_components     -0.0\n",
            "dtype: float64\n",
            "\n",
            "Ст. отклонения (ожид. ≈ 1):\n",
            "numberOfInjuries    1.0\n",
            "numberOfDeaths      1.0\n",
            "modelYear           1.0\n",
            "num_components      1.0\n",
            "dtype: float64\n",
            "\n",
            "\n",
            "\n",
            "Типы данных:\n",
            "crash                  bool\n",
            "fire                   bool\n",
            "numberOfInjuries    float64\n",
            "numberOfDeaths      float64\n",
            "components           object\n",
            "summary              object\n",
            "make                 object\n",
            "model                object\n",
            "modelYear           float64\n",
            "num_components      float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cars_df_standardized['components_list'] = (\n",
        "    cars_df_standardized['components']\n",
        "    .str.split(',')\n",
        "    .apply(lambda x: [i.strip() for i in x] if isinstance(x, list) else [])\n",
        ")\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(cars_df_standardized['components_list'])\n",
        "\n",
        "# Фильтруем редкие компоненты\n",
        "min_support = 50\n",
        "valid_mask = y.sum(axis=0) >= min_support\n",
        "y = y[:, valid_mask]\n",
        "component_names = mlb.classes_[valid_mask]\n",
        "print(f\"Оставлено компонентов: {len(component_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbNYM9Ev5f9B",
        "outputId": "85622eff-eb30-42ff-fc83-976b21a928cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оставлено компонентов: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. X — без summary или с малым TF-IDF\n",
        "X = cars_df_standardized[['make', 'model', 'modelYear']].copy()\n",
        "\n",
        "# 3. Пайплайн — без dense, с малым TF-IDF\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), ['make', 'model']),  # sparse по умолчанию\n",
        "    ('num', 'passthrough', ['modelYear']),\n",
        "    # ('text', TfidfVectorizer(max_features=300, stop_words='english'), 'summary')  # раскомментируй позже\n",
        "], sparse_threshold=1.0)  # сохраняем разреженность"
      ],
      "metadata": {
        "id": "mOiYRfRh51LJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('prep', preprocessor),\n",
        "    ('clf', MultiOutputClassifier(\n",
        "        LGBMClassifier(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=6,\n",
        "            n_jobs=-1,\n",
        "            verbose=-1,\n",
        "            random_state=42\n",
        "        ),\n",
        "        n_jobs=-1  # параллелим по компонентам\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 5. Обучение с таймером\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y.sum(axis=1)\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f\"ОБУЧЕНИЕ ЗАВЕРШЕНО\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SefyB5kp59Mp",
        "outputId": "c7e92597-def8-477a-cdd7-19d17ab631c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ОБУЧЕНИЕ ЗАВЕРШЕНО\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"=== ОСНОВНЫЕ МЕТРИКИ ===\")\n",
        "print(f\"Hamming Loss:     {hamming_loss(y_test, y_pred):.4f} ← чем ниже, тем лучше\")\n",
        "print(f\"F1 Micro:         {f1_score(y_test, y_pred, average='micro'):.4f}\")\n",
        "print(f\"F1 Macro:         {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
        "print(f\"Precision Micro:  {precision_score(y_test, y_pred, average='micro'):.4f}\")\n",
        "print(f\"Recall Micro:     {recall_score(y_test, y_pred, average='micro'):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2afbXaAx8ihg",
        "outputId": "f7d7ef9d-df51-44e1-c053-b9fc5ef13aa0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ОСНОВНЫЕ МЕТРИКИ ===\n",
            "Hamming Loss:     0.0351 ← чем ниже, тем лучше\n",
            "F1 Micro:         0.0833\n",
            "F1 Macro:         0.0406\n",
            "Precision Micro:  0.7027\n",
            "Recall Micro:     0.0443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, hamming_loss\n",
        "import numpy as np\n",
        "\n",
        "print(\"=== ШАГ 1: Получаем вероятности ===\")\n",
        "y_proba = model.predict_proba(X_test)\n",
        "y_proba = np.array([prob[:, 1] for prob in y_proba]).T  # (n_samples, n_components)\n",
        "\n",
        "print(\"=== ШАГ 2: Подбираем лучший порог ===\")\n",
        "thresholds = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
        "best_thresh = 0.1\n",
        "best_f1 = 0\n",
        "\n",
        "for thresh in thresholds:\n",
        "    y_pred = (y_proba > thresh).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred, average='micro')\n",
        "    print(f\"  Порог {thresh:.2f} → F1 Micro: {f1:.4f}\")\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_thresh = thresh\n",
        "\n",
        "print(f\"\\nЛУЧШИЙ ПОРОГ: {best_thresh} → F1 Micro: {best_f1:.4f}\")\n",
        "\n",
        "# === ШАГ 3: Финальные метрики с лучшим порогом ===\n",
        "y_pred_best = (y_proba > best_thresh).astype(int)\n",
        "\n",
        "print(\"\\n=== ФИНАЛЬНЫЕ МЕТРИКИ ===\")\n",
        "print(f\"F1 Micro:     {f1_score(y_test, y_pred_best, average='micro'):.4f}\")\n",
        "print(f\"Precision:    {precision_score(y_test, y_pred_best, average='micro'):.4f}\")\n",
        "print(f\"Recall:       {recall_score(y_test, y_pred_best, average='micro'):.4f}\")\n",
        "print(f\"Hamming Loss: {hamming_loss(y_test, y_pred_best):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8wYRYieMsfl",
        "outputId": "5de855d5-240d-4f75-9965-8a8a7e2db969"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ШАГ 1: Получаем вероятности ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ШАГ 2: Подбираем лучший порог ===\n",
            "  Порог 0.05 → F1 Micro: 0.2546\n",
            "  Порог 0.10 → F1 Micro: 0.3114\n",
            "  Порог 0.15 → F1 Micro: 0.3398\n",
            "  Порог 0.20 → F1 Micro: 0.3348\n",
            "  Порог 0.25 → F1 Micro: 0.2928\n",
            "  Порог 0.30 → F1 Micro: 0.2537\n",
            "\n",
            "ЛУЧШИЙ ПОРОГ: 0.15 → F1 Micro: 0.3398\n",
            "\n",
            "=== ФИНАЛЬНЫЕ МЕТРИКИ ===\n",
            "F1 Micro:     0.3398\n",
            "Precision:    0.2488\n",
            "Recall:       0.5359\n",
            "Hamming Loss: 0.0750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'failure_predictor_v1.pkl')\n",
        "joblib.dump(mlb, 'mlb_components.pkl')\n",
        "joblib.dump(best_thresh, 'best_threshold.pkl')\n",
        "joblib.dump(component_names, 'component_names.pkl')\n",
        "\n",
        "print(\"МОДЕЛЬ СОХРАНЕНА: failure_predictor_v1.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5Y44BPsNAxc",
        "outputId": "345accf6-9316-4330-e953-0108279beda3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "МОДЕЛЬ СОХРАНЕНА: failure_predictor_v1.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_failure(make, model_name, model_year_z, summary=\"\"):\n",
        "    \"\"\"\n",
        "    Предсказывает, какие компоненты могут сломаться\n",
        "    \"\"\"\n",
        "    # Приводим modelYear к z-score (если не знаешь — используй 0.0)\n",
        "    new_car = pd.DataFrame([{\n",
        "        'make': make.upper(),\n",
        "        'model': model_name.upper(),\n",
        "        'modelYear': model_year_z,\n",
        "        'summary': summary\n",
        "    }])\n",
        "\n",
        "    proba = model.predict_proba(new_car)\n",
        "    proba = np.array([p[:, 1] for p in proba]).T[0]\n",
        "\n",
        "    predicted = component_names[proba > best_thresh]\n",
        "    scores = proba[proba > best_thresh]\n",
        "\n",
        "    result = sorted(zip(predicted, scores), key=lambda x: x[1], reverse=True)\n",
        "    return result\n",
        "\n",
        "# Пример:\n",
        "print(\"KIA SORENTO 2016:\")\n",
        "for comp, score in predict_failure('KIA', 'SORENTO', 0.0):\n",
        "    print(f\"  • {comp:20} → {score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "llKJKCqwNBS8",
        "outputId": "64bb84ea-11f4-435f-d971-03c394beb82f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KIA SORENTO 2016:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  • ENGINE               → 0.439\n",
            "  • UNKNOWN OR OTHER     → 0.163\n",
            "  • ELECTRICAL SYSTEM    → 0.152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(\"Запускаем УМНОЕ обучение с summary...\")\n",
        "\n",
        "# 1. Разделяем данные ДО пайплайна\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    X[['make', 'model', 'modelYear', 'summary']], y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Пайплайн БЕЗ TF-IDF\n",
        "preprocessor_no_text = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), ['make', 'model']),\n",
        "    ('num', 'passthrough', ['modelYear'])\n",
        "], sparse_threshold=1.0)\n",
        "\n",
        "# 3. Обучаем базовые признаки\n",
        "print(\"Шаг 1: Обработка make, model, year...\")\n",
        "X_train_base = preprocessor_no_text.fit_transform(X_train_raw[['make', 'model', 'modelYear']])\n",
        "X_test_base = preprocessor_no_text.transform(X_test_raw[['make', 'model', 'modelYear']])\n",
        "\n",
        "# 4. TF-IDF ОТДЕЛЬНО — с малым размером\n",
        "print(\"Шаг 2: TF-IDF по summary...\")\n",
        "tfidf = TfidfVectorizer(max_features=300, stop_words='english', ngram_range=(1,1))\n",
        "X_train_tfidf = tfidf.fit_transform(X_train_raw['summary'])\n",
        "X_test_tfidf = tfidf.transform(X_test_raw['summary'])\n",
        "\n",
        "# 5. Объединяем вручную\n",
        "from scipy.sparse import hstack\n",
        "X_train_final = hstack([X_train_base, X_train_tfidf])\n",
        "X_test_final = hstack([X_test_base, X_test_tfidf])\n",
        "\n",
        "print(f\"Финальная матрица: {X_train_final.shape}\")\n",
        "\n",
        "# 6. Обучаем LightGBM — БЕЗ MultiOutput (быстрее!)\n",
        "print(\"Шаг 3: Обучение LightGBM...\")\n",
        "start = time.time()\n",
        "\n",
        "model_final = MultiOutputClassifier(\n",
        "    LGBMClassifier(n_estimators=80, max_depth=5, n_jobs=1, verbose=-1),  # n_jobs=1!\n",
        "    n_jobs=1  # ОТКЛЮЧИ ПАРАЛЛЕЛИЗМ!\n",
        ")\n",
        "\n",
        "model_final.fit(X_train_final, y_train)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"ГОТОВО ЗА: {(end-start)/60:.1f} МИНУТ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "AWMgF1ngNCmc",
        "outputId": "bc60a652-4f7a-4187-9693-bb39184d8aff"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Запускаем УМНОЕ обучение с summary...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['summary'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1176298763.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 1. Разделяем данные ДО пайплайна\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'make'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'modelYear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'summary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['summary'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, hamming_loss\n",
        "import numpy as np\n",
        "\n",
        "print(\"=== ПОДБОР ЛУЧШЕГО ПОРОГА ===\")\n",
        "y_proba = np.array([est.predict_proba(X_test_final)[:, 1] for est in model_final.estimators_]).T\n",
        "\n",
        "thresholds = [0.05, 0.1, 0.15, 0.2, 0.25]\n",
        "best_thresh = 0.1\n",
        "best_f1 = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred = (y_proba > t).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred, average='micro')\n",
        "    print(f\"  Порог {t:.2f} → F1 Micro: {f1:.4f}\")\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_thresh = t\n",
        "\n",
        "print(f\"\\nЛУЧШИЙ ПОРОГ: {best_thresh} → F1 Micro: {best_f1:.4f}\")\n",
        "\n",
        "# Финальные метрики\n",
        "y_pred_best = (y_proba > best_thresh).astype(int)\n",
        "print(\"\\n=== ФИНАЛЬНЫЕ МЕТРИКИ (с summary) ===\")\n",
        "print(f\"F1 Micro:     {f1_score(y_test, y_pred_best, average='micro'):.4f}\")\n",
        "print(f\"Precision:    {precision_score(y_test, y_pred_best, average='micro'):.4f}\")\n",
        "print(f\"Recall:       {recall_score(y_test, y_pred_best, average='micro'):.4f}\")\n",
        "print(f\"Hamming Loss: {hamming_loss(y_test, y_pred_best):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVyV2RbtNENU",
        "outputId": "b0ca2621-4cc5-40c6-bb5a-7f23ea988856"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ПОДБОР ЛУЧШЕГО ПОРОГА ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Порог 0.05 → F1 Micro: 0.4042\n",
            "  Порог 0.10 → F1 Micro: 0.5031\n",
            "  Порог 0.15 → F1 Micro: 0.5588\n",
            "  Порог 0.20 → F1 Micro: 0.5832\n",
            "  Порог 0.25 → F1 Micro: 0.5950\n",
            "\n",
            "ЛУЧШИЙ ПОРОГ: 0.25 → F1 Micro: 0.5950\n",
            "\n",
            "=== ФИНАЛЬНЫЕ МЕТРИКИ (с summary) ===\n",
            "F1 Micro:     0.5950\n",
            "Precision:    0.5811\n",
            "Recall:       0.6095\n",
            "Hamming Loss: 0.0298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# 1. ЗАГРУЗКА (ПОСЛЕ ПЕРЕЗАПУСКА)\n",
        "# =============================================\n",
        "import joblib\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "print(\"Загружаем модель...\")\n",
        "model = joblib.load('failure_predictor_final.pkl')        # ← Теперь это MultiOutputClassifier!\n",
        "prep = joblib.load('preprocessor_base.pkl')\n",
        "with open('model_metadata.pkl', 'rb') as f:\n",
        "    meta = pickle.load(f)\n",
        "\n",
        "THRESHOLD = meta['best_threshold']\n",
        "COMPONENTS = meta['component_names']\n",
        "\n",
        "# Категории\n",
        "known_makes = prep.named_transformers_['cat'].categories_[0]\n",
        "known_models = prep.named_transformers_['cat'].categories_[1]\n",
        "\n",
        "print(f\"Готово! Порог: {THRESHOLD}, Компонентов: {len(COMPONENTS)}\")\n",
        "print(f\"Марок: {len(known_makes)}, Моделей: {len(known_models)}\")\n",
        "\n",
        "# =============================================\n",
        "# 2. ФУНКЦИЯ ПРЕДСКАЗАНИЯ\n",
        "# =============================================\n",
        "def predict_failures(make, model, year_raw, threshold=THRESHOLD):\n",
        "    make = make.upper().strip()\n",
        "    model = model.upper().strip()\n",
        "\n",
        "    if make not in known_makes:\n",
        "        return [(\"НЕИЗВЕСТНАЯ МАРКА\", 0.0)]\n",
        "    if model not in known_models:\n",
        "        return [(\"НЕИЗВЕСТНАЯ МОДЕЛЬ\", 0.0)]\n",
        "\n",
        "    try:\n",
        "        year_z = (year_raw - 2015) / 3\n",
        "        df = pd.DataFrame([{'make': make, 'model': model, 'modelYear': year_z}])\n",
        "        X = prep.transform(df[['make', 'model', 'modelYear']])\n",
        "\n",
        "        if X.nnz == 0:\n",
        "            return [(\"НЕТ ДАННЫХ\", 0.0)]\n",
        "\n",
        "        proba = np.array([est.predict_proba(X)[:, 1][0] for est in model.estimators_])\n",
        "        mask = proba > threshold\n",
        "        if not mask.any():\n",
        "            return [(\"РИСКИ МИНИМАЛЬНЫ\", 0.0)]\n",
        "\n",
        "        risks = (proba[mask] * 100).round(1)\n",
        "        comps = COMPONENTS[mask]\n",
        "        return sorted(zip(comps, risks), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    except Exception as e:\n",
        "        return [(\"ОШИБКА\", 0.0), (str(e)[:50], 0.0)]\n",
        "\n",
        "# =============================================\n",
        "# 3. ТЕСТ НА РЕАЛЬНЫХ МАРКАХ\n",
        "# =============================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ПРЕДСКАЗАНИЕ ДЛЯ ПОПУЛЯРНЫХ АВТО\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_cars = [\n",
        "    ('NISSAN', 'ROGUE', 2016),\n",
        "    ('FORD', 'ESCAPE', 2014),\n",
        "    ('TOYOTA', 'SIENNA', 2018),\n",
        "    ('HONDA', 'CIVIC', 2011),\n",
        "    ('CHEVROLET', 'EQUINOX', 2015),\n",
        "]\n",
        "\n",
        "for make, model, year in test_cars:\n",
        "    print(f\"\\n{make} {model} {year}:\")\n",
        "    results = predict_failures(make, model, year)\n",
        "    for comp, risk in results:\n",
        "        print(f\"  • {comp:25} → {risk:5.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMaNzrC9Vxlx",
        "outputId": "26b6dbb0-63b7-4dc9-c7da-cad0f769c2c8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загружаем модель...\n",
            "Готово! Порог: 0.25, Компонентов: 40\n",
            "Марок: 331, Моделей: 1747\n",
            "\n",
            "============================================================\n",
            "ПРЕДСКАЗАНИЕ ДЛЯ ПОПУЛЯРНЫХ АВТО\n",
            "============================================================\n",
            "\n",
            "NISSAN ROGUE 2016:\n",
            "  • ОШИБКА                    →   0.0%\n",
            "  • 'str' object has no attribute 'estimators_' →   0.0%\n",
            "\n",
            "FORD ESCAPE 2014:\n",
            "  • ОШИБКА                    →   0.0%\n",
            "  • 'str' object has no attribute 'estimators_' →   0.0%\n",
            "\n",
            "TOYOTA SIENNA 2018:\n",
            "  • ОШИБКА                    →   0.0%\n",
            "  • 'str' object has no attribute 'estimators_' →   0.0%\n",
            "\n",
            "HONDA CIVIC 2011:\n",
            "  • ОШИБКА                    →   0.0%\n",
            "  • 'str' object has no attribute 'estimators_' →   0.0%\n",
            "\n",
            "CHEVROLET EQUINOX 2015:\n",
            "  • ОШИБКА                    →   0.0%\n",
            "  • 'str' object has no attribute 'estimators_' →   0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bA9OdnznWaBC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}